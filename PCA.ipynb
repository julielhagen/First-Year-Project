{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d385186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "from skimage.transform import resize, rescale\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1470beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_im(im_id, im_dir_path = \"\", scalar = 1, output_shape = None):\n",
    "    '''Prepare image from im_id and optional dictory path.\n",
    "    If directory path is not passed, the whole filepath, including filetype notation, \n",
    "    should be given as im_id. If parameter scalar is passed, output image will be scaled by it. \n",
    "    Defualt 1 retains original size.\n",
    "    \n",
    "    Args:\n",
    "        im_id (str): image ID\n",
    "        im_dir_path (str, optional): image directory path\n",
    "        scalar (float, optional): rescale coefficient\n",
    "\n",
    "    Returns:\n",
    "        im (numpy.ndarray): image.\n",
    "    '''\n",
    "\n",
    "    # Read and resize image\n",
    "    if im_dir_path == \"\":\n",
    "        im = plt.imread(im_id)[:, :, :3] #Some images have fourth, empty color chanel which we slice of here\n",
    "    else:\n",
    "        im = plt.imread(im_dir_path + im_id)[:, :, :3] #Some images have fourth, empty color chanel which we slice of here\n",
    "    im = rescale(im, scalar, anti_aliasing=True, channel_axis = 2) #IDWE: Use channel_axis=2 to prevent picture from being turned bianry when rescaled\n",
    "    if output_shape != None:\n",
    "        im = resize(im, output_shape)\n",
    "\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c5c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "image_folder_path = \"test_images\"\n",
    "n_images = 100\n",
    "paths = [f for f in listdir(image_folder_path) if isfile(join(image_folder_path, f))][:n_images]\n",
    "\n",
    "images = []\n",
    "for im_path in paths:\n",
    "  image = prep_im(im_path, \"test_images/\", output_shape = (300,300))\n",
    "\n",
    "  #image = Image.open(join(image_folder_path, im_path))\n",
    "  #image = resize(image, (300,300)) # Make sure the image has the same size\n",
    "  arr = np.asarray(image)\n",
    "  images.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5284f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load labels for images\n",
    "data = np.array([i.strip().split(',') for i in open('metadata.csv')])\n",
    "\n",
    "mask = data == ''\n",
    "data[np.where(mask)] = np.nan\n",
    "\n",
    "labels = np.asarray([data[np.where(data[:,-2]==paths[i])[0][0],17] for i in range(len(paths))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd93faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 270000)\n"
     ]
    }
   ],
   "source": [
    "# Flatten it, now each row represents a single image\n",
    "X = np.stack(images, axis = 0)\n",
    "\n",
    "dim1, dim2, chan = arr.shape\n",
    "n_features = chan*dim1*dim2\n",
    "X = X.reshape((len(images), n_features)) # flattened --> this goes to PCA\n",
    "\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9c89e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the model (a.k.a. specify the hyper-parameters e.g. number of components)\n",
    "final_n_features = 100 # Hyper-parameter - try different values\n",
    "pca = PCA(n_components=final_n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aa0b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size= 0.2, random_state =1,stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ed065a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=100 must be between 0 and min(n_samples, n_features)=72 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Transformed features\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train_transformed \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# X_new has final_n_features --> this can be fed to the classfier model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m X_train_recovered \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39minverse_transform(X_train_transformed)\n\u001b[1;32m      5\u001b[0m X_test_transformed \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit_transform(X_test) \u001b[38;5;66;03m# X_new has final_n_features --> this can be fed to the classfier model\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:407\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 407\u001b[0m     U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m     U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhiten:\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;66;03m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:457\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_truncated(X, n_components, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:475\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    472\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is only supported if n_samples >= n_features\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    473\u001b[0m         )\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n_components \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_samples, n_features):\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m must be between 0 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin(n_samples, n_features)=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd_solver=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_components, \u001b[38;5;28mmin\u001b[39m(n_samples, n_features))\n\u001b[1;32m    479\u001b[0m     )\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n_components \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n_components, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "\u001b[0;31mValueError\u001b[0m: n_components=100 must be between 0 and min(n_samples, n_features)=72 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "# Transformed features\n",
    "X_train_transformed = pca.fit_transform(X_train) # X_new has final_n_features --> this can be fed to the classfier model\n",
    "X_train_recovered = pca.inverse_transform(X_train_transformed)\n",
    "\n",
    "X_test_transformed = pca.fit_transform(X_test) # X_new has final_n_features --> this can be fed to the classfier model\n",
    "X_test_recovered = pca.inverse_transform(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbf77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train_recovered[10,:].reshape(300,300,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[10,:].reshape(300,300,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a classifer\n",
    "clf = KNeighborsClassifier(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa73915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train it --> need to define y first\n",
    "clf.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf45c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Predict on validation dataset and measure accuracy, f1-score\n",
    "clf.predict(X_test_transformed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f532e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy of our model on the test data\n",
    "clf.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8628b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = list(range(5,151,10))\n",
    "neighbors = list(range(1,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb68bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for component in components:\n",
    "    pca = PCA(n_components=component)\n",
    "    \n",
    "    X_train_transformed = pca.fit_transform(X_train) # X_new has final_n_features --> this can be fed to the classfier model\n",
    "    X_train_recovered = pca.inverse_transform(X_train_transformed)\n",
    "\n",
    "    X_test_transformed = pca.fit_transform(X_test) # X_new has final_n_features --> this can be fed to the classfier model\n",
    "    X_test_recovered = pca.inverse_transform(X_test_transformed)\n",
    "    \n",
    "    for n in neighbors:\n",
    "        clf = KNeighborsClassifier(n_neighbors=n)\n",
    "        \n",
    "        clf.fit(X_train_transformed, y_train)\n",
    "        \n",
    "        clf.predict(X_test_transformed)\n",
    "        \n",
    "        score = clf.score(X_test_transformed, y_test)\n",
    "        \n",
    "        print(f'Components: {component}, neighbors: {n}, Score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83c5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
